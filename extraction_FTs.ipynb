{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Extraction des informations PDF du dossier FTs\n",
        "\n",
        "Ce notebook extrait pour **chaque PDF** du dossier `FTs` :\n",
        "- **ISIN**\n",
        "- **Issuer** (détecté parmi la liste connue)\n",
        "- **Nombre d'occurrences** de chaque mot choisi (insensible à la casse et aux accents)\n",
        "\n",
        "Si une étape échoue (ex. issuer non détecté), les autres champs (ISIN, comptages) sont quand même remplis.\n",
        "\n",
        "Modifiez la liste `MOTS_A_COMPTER` ci-dessous pour choisir les mots à compter."
      ],
      "id": "a283aa8a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import re\n",
        "import unicodedata\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import pdfplumber\n",
        "\n",
        "# --- Liste des issuers reconnus (ordre longueur décroissante pour éviter sous-chaînes) ---\n",
        "LISTE_ISSUERS = [\n",
        "    \"Merrill Lynch\", \"Bank of America\", \"Morgan Stanley\", \"Société Générale\",\n",
        "    \"Societe Generale\", \"Societe General\", \"Deutsche Bank\", \"Deutsch Bank\",\n",
        "    \"Crédit Agricole\", \"Credit Agricole\", \"UniCredit\", \"uni credit\",\n",
        "    \"BNP Paribas\", \"Citigroup\", \"Leonteq\", \"Santander\", \"Natixis\", \"Barclays\",\n",
        "    \"JPMorgan\", \"J.M. Morgan\", \"Goldman Sachs\", \"Goldman\", \"HSBC\", \"Nomura\",\n",
        "    \"UBS\", \"BOFA\", \"Citi\", \"RBC\",\n",
        "]\n",
        "ISSUER_CANONIQUE = {\n",
        "    \"bofa\": \"Bank of America\", \"bank of america\": \"Bank of America\", \"merrill lynch\": \"Bank of America\",\n",
        "    \"citi\": \"Citigroup\", \"citigroup\": \"Citigroup\",\n",
        "    \"société générale\": \"Société Générale\", \"societe generale\": \"Société Générale\", \"societe general\": \"Société Générale\",\n",
        "    \"deutsche bank\": \"Deutsche Bank\", \"deutsch bank\": \"Deutsche Bank\",\n",
        "    \"unicredit\": \"UniCredit\", \"uni credit\": \"UniCredit\",\n",
        "    \"jpmorgan\": \"JPMorgan\", \"j.m. morgan\": \"JPMorgan\",\n",
        "    \"goldman\": \"Goldman Sachs\", \"goldman sachs\": \"Goldman Sachs\",\n",
        "}\n",
        "\n",
        "def normaliser(texte):\n",
        "    if not texte:\n",
        "        return \"\"\n",
        "    nfd = unicodedata.normalize(\"NFD\", texte.lower())\n",
        "    return \"\".join(c for c in nfd if unicodedata.category(c) != \"Mn\")\n",
        "\n",
        "def extraire_texte_pdf(chemin):\n",
        "    blocs = []\n",
        "    with pdfplumber.open(chemin) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            t = page.extract_text()\n",
        "            if t:\n",
        "                blocs.append(t)\n",
        "    return \"\\n\".join(blocs)\n",
        "\n",
        "def extraire_isin(texte):\n",
        "    m = re.search(r\"\\b([A-Z]{2}[A-Z0-9]{9}[0-9])\\b\", texte, re.IGNORECASE)\n",
        "    return m.group(1).upper() if m else None\n",
        "\n",
        "def extraire_issuer(texte):\n",
        "    texte_n = normaliser(texte)\n",
        "    ordered = sorted(LISTE_ISSUERS, key=len, reverse=True)\n",
        "    for nom in ordered:\n",
        "        nom_n = normaliser(nom)\n",
        "        if nom_n and nom_n in texte_n:\n",
        "            return ISSUER_CANONIQUE.get(nom_n, nom)\n",
        "    return None\n",
        "\n",
        "def compter_mot(texte, mot_test):\n",
        "    if not texte or not mot_test:\n",
        "        return 0\n",
        "    texte_n = normaliser(texte)\n",
        "    mot_n = normaliser(mot_test)\n",
        "    motif = r\"\\b\" + re.escape(mot_n) + r\"\\b\"\n",
        "    return len(re.findall(motif, texte_n))\n",
        "\n",
        "def _cle_nb(mot):\n",
        "    return \"nb_\" + mot.replace(\" \", \"_\")\n",
        "\n",
        "def extraire_infos_pdf(chemin_pdf, mots_test=None):\n",
        "    if mots_test is None:\n",
        "        mots_test = [\"mot_test\"]\n",
        "    if isinstance(mots_test, str):\n",
        "        mots_test = [mots_test]\n",
        "    chemin = Path(chemin_pdf)\n",
        "    if not chemin.exists():\n",
        "        raise FileNotFoundError(f\"PDF introuvable: {chemin}\")\n",
        "    try:\n",
        "        texte = extraire_texte_pdf(chemin)\n",
        "    except Exception as e:\n",
        "        out = {\"isin\": None, \"issuer\": None, \"erreur\": str(e)}\n",
        "        for mot in mots_test:\n",
        "            out[_cle_nb(mot)] = None\n",
        "        return out\n",
        "    try:\n",
        "        isin = extraire_isin(texte)\n",
        "    except Exception:\n",
        "        isin = None\n",
        "    try:\n",
        "        issuer = extraire_issuer(texte)\n",
        "    except Exception:\n",
        "        issuer = None\n",
        "    out = {\"isin\": isin, \"issuer\": issuer}\n",
        "    for mot in mots_test:\n",
        "        try:\n",
        "            out[_cle_nb(mot)] = compter_mot(texte, mot)\n",
        "        except Exception:\n",
        "            out[_cle_nb(mot)] = None\n",
        "    return out\n",
        "\n",
        "# --- Paramètres (dossiers et mots à compter) ---\n",
        "DOSSIER_FTS = Path(\"FTs\")\n",
        "DOSSIER_RESULTATS = Path(\"Extraction Result\")\n",
        "MOTS_A_COMPTER = [\"risque\", \"crédit\"]"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "474a720c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Liste de tous les PDF dans FTs\n",
        "fichiers_pdf = sorted(DOSSIER_FTS.glob(\"*.pdf\"))\n",
        "print(f\"{len(fichiers_pdf)} fichier(s) PDF trouvé(s) dans {DOSSIER_FTS}\")\n",
        "for f in fichiers_pdf:\n",
        "    print(f\"  - {f.name}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Extraction des infos pour chaque PDF (une erreur sur une étape ne bloque pas les autres)\n",
        "resultats = []\n",
        "for chemin in fichiers_pdf:\n",
        "    try:\n",
        "        infos = extraire_infos_pdf(chemin, mots_test=MOTS_A_COMPTER)\n",
        "        ligne = {\"fichier\": chemin.name, \"isin\": infos[\"isin\"], \"issuer\": infos[\"issuer\"]}\n",
        "        for mot in MOTS_A_COMPTER:\n",
        "            cle = f\"nb_{mot.replace(' ', '_')}\"\n",
        "            ligne[cle] = infos.get(cle)\n",
        "        if \"erreur\" in infos:\n",
        "            ligne[\"erreur\"] = infos[\"erreur\"]\n",
        "        resultats.append(ligne)\n",
        "    except Exception as e:\n",
        "        ligne = {\"fichier\": chemin.name, \"isin\": None, \"issuer\": None, \"erreur\": str(e)}\n",
        "        for mot in MOTS_A_COMPTER:\n",
        "            ligne[f\"nb_{mot.replace(' ', '_')}\"] = None\n",
        "        resultats.append(ligne)\n",
        "\n",
        "df = pd.DataFrame(resultats)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "34d26d6d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Export Excel dans le dossier \"Extraction Result\"\n",
        "DOSSIER_RESULTATS.mkdir(parents=True, exist_ok=True)\n",
        "fichier_excel = DOSSIER_RESULTATS / \"extraction_FTs.xlsx\"\n",
        "df.to_excel(fichier_excel, index=False, engine=\"openpyxl\")\n",
        "print(f\"Résultats exportés dans {fichier_excel}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "7e40a0bb"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}